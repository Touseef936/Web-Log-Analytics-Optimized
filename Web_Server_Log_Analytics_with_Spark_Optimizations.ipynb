{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web Server Log Analytics with Spark Optimizations\n"
      ],
      "metadata": {
        "id": "2U4wIHiVCoIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "df_logs= None\n",
        "spark=SparkSession.builder\\\n",
        "     .appName(\"WebLogAnalytics\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .getOrCreate()\n",
        ""
      ],
      "metadata": {
        "id": "A5ng1Klq_zb7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample Raw Log Data (in place of real log file)"
      ],
      "metadata": {
        "id": "4DOmzCL6Ai-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_data = [\n",
        "    (\"192.168.1.1\", \"2023-07-01 10:00:00\", \"/home\", 200),\n",
        "    (\"192.168.1.2\", \"2023-07-01 10:01:00\", \"/login\", 200),\n",
        "    (\"192.168.1.3\", \"2023-07-01 10:02:00\", \"/cart\", 500),\n",
        "    (\"192.168.1.1\", \"2023-07-01 10:03:00\", \"/checkout\", 404),\n",
        "    (\"192.168.1.2\", \"2023-07-01 10:04:00\", \"/home\", 200),\n",
        "    (\"192.168.1.3\", \"2023-07-01 10:05:00\", \"/home\", 200)\n",
        "]\n",
        "\n",
        "columns = [\"ip\", \"timestamp\", \"url\", \"status\"]\n",
        "df_logs = spark.createDataFrame(log_data, columns)\n",
        "\n",
        "# Convert timestamp column to proper type\n",
        "df_logs = df_logs.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))"
      ],
      "metadata": {
        "id": "ViSI-a0JAnF3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Column + Predicate + Filter + Project Pushdown simulated with select/filter"
      ],
      "metadata": {
        "id": "cwi44B_uAvuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_logs.select(\"ip\", \"url\", \"status\", \"timestamp\") \\\n",
        "    .filter(\"status >= 400\")"
      ],
      "metadata": {
        "id": "MC19LurmA3zf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cache for reuse"
      ],
      "metadata": {
        "id": "4JzvuY4oA9Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cached_errors = df_filtered.cache()"
      ],
      "metadata": {
        "id": "43DJvbgLA_Xs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by URL to find most common errors\n",
        "error_counts = cached_errors.groupBy(\"url\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "# Broadcast Join with small IP-to-country mapping\n",
        "ip_country = [\n",
        "    (\"192.168.1.1\", \"US\"),\n",
        "    (\"192.168.1.2\", \"UK\"),\n",
        "    (\"192.168.1.3\", \"PK\")\n",
        "]\n",
        "df_country = spark.createDataFrame(ip_country, [\"ip\", \"country\"])\n",
        "df_joined = cached_errors.join(broadcast(df_country), \"ip\")\n",
        "\n",
        "# Skew join simulation with salting\n",
        "salted_logs = df_logs.withColumn(\"salted_ip\", concat(col(\"ip\"), (rand()*10).cast(\"int\")))\n",
        "\n",
        "# Repartition by URL\n",
        "reparted = df_logs.repartition(4, \"url\")\n",
        "\n",
        "# Coalesce to write final output\n",
        "reparted.coalesce(1).write.mode(\"overwrite\").parquet(\"/tmp/final_logs\")\n",
        "\n",
        "# Save optimized file format with max record size\n",
        "reparted.write.option(\"maxRecordsPerFile\", 100000).parquet(\"/tmp/optimized_logs\")\n",
        "\n",
        "# Show final analysis\n",
        "print(\"most commen error urls\")\n",
        "error_counts.show()\n",
        "\n",
        "print(\"join with country info\")\n",
        "df_joined.show()\n",
        "\n",
        "# Monitor Spark UI: http://localhost:4040\n",
        "# Stop session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eNCYwwaBOO1",
        "outputId": "5ad6e474-9aa9-427e-fd7c-3089ba5c9243"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Most Common Error URLs ---\n",
            "+---------+-----+\n",
            "|      url|count|\n",
            "+---------+-----+\n",
            "|    /cart|    1|\n",
            "|/checkout|    1|\n",
            "+---------+-----+\n",
            "\n",
            "--- Joined With Country Info ---\n",
            "+-----------+---------+------+-------------------+-------+\n",
            "|         ip|      url|status|          timestamp|country|\n",
            "+-----------+---------+------+-------------------+-------+\n",
            "|192.168.1.3|    /cart|   500|2023-07-01 10:02:00|     PK|\n",
            "|192.168.1.1|/checkout|   404|2023-07-01 10:03:00|     US|\n",
            "+-----------+---------+------+-------------------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}